{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0580d66f-5aef-4355-9337-e10d699d0279",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install silence_tensorflow tensorflow scikit-learn tqdm numpy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10b44c4-ccfa-4a4e-9dc6-2da8fe72e242",
   "metadata": {},
   "source": [
    "### 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed69485-060e-4df7-a68b-2d8526a033d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout\n",
    "\n",
    "# 시드값 고정\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 0번 GPU만 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7225f03b-7842-4ea8-8bfe-197774a3dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "npy_files = [f for f in os.listdir('./data/train_npy/') if f.endswith('.npy')] # 훈련 npy 파일이 들어있는 폴더 경로\n",
    "\n",
    "spectrogram_shapes = {}\n",
    "for file in npy_files:\n",
    "    data = np.load(f\"./data/train_npy/{file}\") # 훈련 npy 파일이 들어있는 경로를 {file}앞까지 삽입\n",
    "    spectrogram_shapes[file] = data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56335506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_zero_padding(spectrogram, max_length):\n",
    "    padding_length = max_length - spectrogram.shape[1]\n",
    "    if padding_length > 0:\n",
    "        return np.pad(spectrogram, ((0, 0), (0, padding_length)), 'constant')\n",
    "    else:\n",
    "        return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc376cd9-ceb3-490e-82eb-ca6624ff3d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 긴 시간 축의 길이를 찾습니다.\n",
    "max_time_length = max(shape[1] for shape in spectrogram_shapes.values())\n",
    "\n",
    "padded_spectrograms = {}\n",
    "for file, shape in spectrogram_shapes.items():\n",
    "    spectrogram = np.load(f\"./data/train_npy/{file}\") # 훈련 npy 파일이 들어있는 폴더 경로\n",
    "    padded_spectrogram = apply_zero_padding(spectrogram, max_time_length)\n",
    "    padded_spectrograms[file] = padded_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4b2321b-b11e-4845-a120-400ea1cf22e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv('./data/train.csv') # 정답 레이블이 있는 csv 파일의 경로\n",
    "labels_dict = labels_df.set_index('file').to_dict()['label']\n",
    "padded_data_labels = [labels_dict[file] for file in padded_spectrograms.keys()]\n",
    "\n",
    "padded_data_array = np.array(list(padded_spectrograms.values()), dtype='float32')\n",
    "padded_data_labels = np.array(padded_data_labels, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09cadc71-816f-44e8-b733-61abb46ca31e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    padded_data_array,\n",
    "    padded_data_labels,\n",
    "    test_size=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = {classes[i]: class_weights[i] for i in range(len(classes))}\n",
    "\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], X_train.shape[2], 1))\n",
    "X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], X_val.shape[2], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2946ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleCNN_1(input_shape):\n",
    "    model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    Conv2D(24, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),    \n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(56, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def simpleCNN_2(input_shape):\n",
    "    model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    Conv2D(24, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),    \n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    Conv2D(40, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(56, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def simpleCNN_3(input_shape):\n",
    "    model = Sequential([\n",
    "    Conv2D(16, (3, 3), activation='relu', padding='same', input_shape=input_shape),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    Conv2D(24, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),    \n",
    "    Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    Conv2D(40, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    Conv2D(48, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    MaxPooling2D(2, 2, padding='same'),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(56, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f66a94-27f3-486e-8b11-253f1bb53e31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = simpleCNN_1(input_shape=(X_train.shape[1], X_train.shape[2], 1)) # 앙상블을 사용하기 때문에 3개의 모델을 모두 훈련하여야 합니다.\n",
    "#model = simpleCNN_2(input_shape=(X_train.shape[1], X_train.shape[2], 1))\n",
    "#model = simpleCNN_3(input_shape=(X_train.shape[1], X_train.shape[2], 1))\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  \n",
    "    patience=60,         \n",
    "    verbose=1,           \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model_v1.h5', # val_loss가 가장 낮은 가중치 파일 저장, 모델 마다 이름을 다르게 저장해야 합니다.\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7809e0c-d692-4d0f-9a79-d5a9bab5a782",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 6.1354 - accuracy: 0.6519\n",
      "Epoch 1: val_loss improved from inf to 0.67306, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 14s 38ms/step - loss: 6.1354 - accuracy: 0.6519 - val_loss: 0.6731 - val_accuracy: 0.7400 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 1.5075 - accuracy: 0.6841\n",
      "Epoch 2: val_loss improved from 0.67306 to 0.65542, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 31ms/step - loss: 1.5240 - accuracy: 0.6833 - val_loss: 0.6554 - val_accuracy: 0.7433 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.9203 - accuracy: 0.6780\n",
      "Epoch 3: val_loss improved from 0.65542 to 0.64106, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.9203 - accuracy: 0.6780 - val_loss: 0.6411 - val_accuracy: 0.7467 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.8758 - accuracy: 0.6725\n",
      "Epoch 4: val_loss did not improve from 0.64106\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.8735 - accuracy: 0.6713 - val_loss: 0.6634 - val_accuracy: 0.7150 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.8090 - accuracy: 0.6536\n",
      "Epoch 5: val_loss improved from 0.64106 to 0.63994, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.8082 - accuracy: 0.6533 - val_loss: 0.6399 - val_accuracy: 0.7583 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.7445 - accuracy: 0.6670\n",
      "Epoch 6: val_loss improved from 0.63994 to 0.63931, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.7441 - accuracy: 0.6670 - val_loss: 0.6393 - val_accuracy: 0.7600 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.7447 - accuracy: 0.6437\n",
      "Epoch 7: val_loss improved from 0.63931 to 0.63171, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 31ms/step - loss: 0.7438 - accuracy: 0.6446 - val_loss: 0.6317 - val_accuracy: 0.7567 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.7265 - accuracy: 0.6598\n",
      "Epoch 8: val_loss did not improve from 0.63171\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.7263 - accuracy: 0.6598 - val_loss: 0.6392 - val_accuracy: 0.7583 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.7276 - accuracy: 0.6244\n",
      "Epoch 9: val_loss did not improve from 0.63171\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.7276 - accuracy: 0.6235 - val_loss: 0.6487 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6825 - accuracy: 0.6201\n",
      "Epoch 10: val_loss did not improve from 0.63171\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.6824 - accuracy: 0.6204 - val_loss: 0.6362 - val_accuracy: 0.7567 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.6233\n",
      "Epoch 11: val_loss improved from 0.63171 to 0.63110, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.6737 - accuracy: 0.6235 - val_loss: 0.6311 - val_accuracy: 0.7633 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6830 - accuracy: 0.6291\n",
      "Epoch 12: val_loss improved from 0.63110 to 0.62315, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.6828 - accuracy: 0.6302 - val_loss: 0.6231 - val_accuracy: 0.7717 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.7056 - accuracy: 0.6051\n",
      "Epoch 13: val_loss did not improve from 0.62315\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.7054 - accuracy: 0.6050 - val_loss: 0.6481 - val_accuracy: 0.6733 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.6207\n",
      "Epoch 14: val_loss did not improve from 0.62315\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.6710 - accuracy: 0.6202 - val_loss: 0.6318 - val_accuracy: 0.7283 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6682 - accuracy: 0.6239\n",
      "Epoch 15: val_loss did not improve from 0.62315\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.6680 - accuracy: 0.6243 - val_loss: 0.6288 - val_accuracy: 0.7050 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.6217\n",
      "Epoch 16: val_loss did not improve from 0.62315\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.6695 - accuracy: 0.6217 - val_loss: 0.6360 - val_accuracy: 0.7017 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6556 - accuracy: 0.6469\n",
      "Epoch 17: val_loss did not improve from 0.62315\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.6552 - accuracy: 0.6478 - val_loss: 0.6285 - val_accuracy: 0.7150 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.7224 - accuracy: 0.6360\n",
      "Epoch 18: val_loss did not improve from 0.62315\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.7220 - accuracy: 0.6361 - val_loss: 0.6245 - val_accuracy: 0.7450 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.7023 - accuracy: 0.6055\n",
      "Epoch 19: val_loss did not improve from 0.62315\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.7038 - accuracy: 0.6046 - val_loss: 0.6261 - val_accuracy: 0.7483 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6922 - accuracy: 0.6257\n",
      "Epoch 20: val_loss improved from 0.62315 to 0.61186, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.6918 - accuracy: 0.6259 - val_loss: 0.6119 - val_accuracy: 0.7517 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6574 - accuracy: 0.6332\n",
      "Epoch 21: val_loss improved from 0.61186 to 0.59934, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.6569 - accuracy: 0.6339 - val_loss: 0.5993 - val_accuracy: 0.7633 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6539 - accuracy: 0.6357\n",
      "Epoch 22: val_loss improved from 0.59934 to 0.59444, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.6537 - accuracy: 0.6363 - val_loss: 0.5944 - val_accuracy: 0.7533 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6541 - accuracy: 0.6488\n",
      "Epoch 23: val_loss did not improve from 0.59444\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.6539 - accuracy: 0.6496 - val_loss: 0.6160 - val_accuracy: 0.7050 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6336 - accuracy: 0.6632\n",
      "Epoch 24: val_loss improved from 0.59444 to 0.56349, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.6339 - accuracy: 0.6630 - val_loss: 0.5635 - val_accuracy: 0.7800 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.6753 - accuracy: 0.6577\n",
      "Epoch 25: val_loss did not improve from 0.56349\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.6738 - accuracy: 0.6587 - val_loss: 0.6092 - val_accuracy: 0.7533 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6372 - accuracy: 0.6782\n",
      "Epoch 26: val_loss did not improve from 0.56349\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.6369 - accuracy: 0.6785 - val_loss: 0.5665 - val_accuracy: 0.7783 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6113 - accuracy: 0.7048\n",
      "Epoch 27: val_loss improved from 0.56349 to 0.54222, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.6109 - accuracy: 0.7054 - val_loss: 0.5422 - val_accuracy: 0.8033 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.5881 - accuracy: 0.7282\n",
      "Epoch 28: val_loss did not improve from 0.54222\n",
      "169/169 [==============================] - 5s 31ms/step - loss: 0.5880 - accuracy: 0.7281 - val_loss: 0.5605 - val_accuracy: 0.7483 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.5555 - accuracy: 0.7610\n",
      "Epoch 29: val_loss improved from 0.54222 to 0.51405, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.5548 - accuracy: 0.7615 - val_loss: 0.5141 - val_accuracy: 0.7933 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.7487\n",
      "Epoch 30: val_loss improved from 0.51405 to 0.51283, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.6760 - accuracy: 0.7480 - val_loss: 0.5128 - val_accuracy: 0.8050 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.5403 - accuracy: 0.7854\n",
      "Epoch 31: val_loss improved from 0.51283 to 0.44124, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.5398 - accuracy: 0.7859 - val_loss: 0.4412 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.5304 - accuracy: 0.7791\n",
      "Epoch 32: val_loss did not improve from 0.44124\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.5304 - accuracy: 0.7791 - val_loss: 0.4642 - val_accuracy: 0.8183 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.5090 - accuracy: 0.7991\n",
      "Epoch 33: val_loss improved from 0.44124 to 0.40629, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.5089 - accuracy: 0.7991 - val_loss: 0.4063 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4693 - accuracy: 0.8207\n",
      "Epoch 34: val_loss improved from 0.40629 to 0.40379, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.4693 - accuracy: 0.8207 - val_loss: 0.4038 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.5082 - accuracy: 0.8278\n",
      "Epoch 35: val_loss did not improve from 0.40379\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.5081 - accuracy: 0.8274 - val_loss: 0.4900 - val_accuracy: 0.7967 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4787 - accuracy: 0.8209\n",
      "Epoch 36: val_loss did not improve from 0.40379\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.4787 - accuracy: 0.8209 - val_loss: 0.4258 - val_accuracy: 0.8417 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4540 - accuracy: 0.8361\n",
      "Epoch 37: val_loss did not improve from 0.40379\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4524 - accuracy: 0.8367 - val_loss: 0.4729 - val_accuracy: 0.8483 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4539 - accuracy: 0.8376\n",
      "Epoch 38: val_loss did not improve from 0.40379\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.4534 - accuracy: 0.8374 - val_loss: 0.4217 - val_accuracy: 0.8383 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4455 - accuracy: 0.8411\n",
      "Epoch 39: val_loss did not improve from 0.40379\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4459 - accuracy: 0.8411 - val_loss: 0.4439 - val_accuracy: 0.8417 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4387 - accuracy: 0.8507\n",
      "Epoch 40: val_loss did not improve from 0.40379\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.4382 - accuracy: 0.8509 - val_loss: 0.4510 - val_accuracy: 0.8267 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4836 - accuracy: 0.8307\n",
      "Epoch 41: val_loss improved from 0.40379 to 0.39577, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4830 - accuracy: 0.8311 - val_loss: 0.3958 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4513 - accuracy: 0.8393\n",
      "Epoch 42: val_loss did not improve from 0.39577\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.4513 - accuracy: 0.8393 - val_loss: 0.4296 - val_accuracy: 0.8417 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4432 - accuracy: 0.8448\n",
      "Epoch 43: val_loss did not improve from 0.39577\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4432 - accuracy: 0.8448 - val_loss: 0.4041 - val_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4350 - accuracy: 0.8482\n",
      "Epoch 44: val_loss did not improve from 0.39577\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4370 - accuracy: 0.8474 - val_loss: 0.4013 - val_accuracy: 0.8567 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.8341\n",
      "Epoch 45: val_loss did not improve from 0.39577\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4738 - accuracy: 0.8344 - val_loss: 0.3990 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4554 - accuracy: 0.8250\n",
      "Epoch 46: val_loss improved from 0.39577 to 0.39082, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.4552 - accuracy: 0.8252 - val_loss: 0.3908 - val_accuracy: 0.8567 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4782 - accuracy: 0.8257\n",
      "Epoch 47: val_loss did not improve from 0.39082\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4776 - accuracy: 0.8263 - val_loss: 0.3947 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4608 - accuracy: 0.8335\n",
      "Epoch 48: val_loss did not improve from 0.39082\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4611 - accuracy: 0.8335 - val_loss: 0.4076 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4742 - accuracy: 0.8313\n",
      "Epoch 49: val_loss did not improve from 0.39082\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4735 - accuracy: 0.8313 - val_loss: 0.4183 - val_accuracy: 0.8517 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4972 - accuracy: 0.8454\n",
      "Epoch 50: val_loss did not improve from 0.39082\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4978 - accuracy: 0.8454 - val_loss: 0.3961 - val_accuracy: 0.8633 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4391 - accuracy: 0.8428\n",
      "Epoch 51: val_loss improved from 0.39082 to 0.37340, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 31ms/step - loss: 0.4384 - accuracy: 0.8431 - val_loss: 0.3734 - val_accuracy: 0.8683 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4411 - accuracy: 0.8507\n",
      "Epoch 52: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4411 - accuracy: 0.8507 - val_loss: 0.3825 - val_accuracy: 0.8700 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4157 - accuracy: 0.8532\n",
      "Epoch 53: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4160 - accuracy: 0.8531 - val_loss: 0.3768 - val_accuracy: 0.8733 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4148 - accuracy: 0.8616\n",
      "Epoch 54: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4150 - accuracy: 0.8613 - val_loss: 0.3931 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4258 - accuracy: 0.8557\n",
      "Epoch 55: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4260 - accuracy: 0.8559 - val_loss: 0.4220 - val_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4132 - accuracy: 0.8588\n",
      "Epoch 56: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4137 - accuracy: 0.8587 - val_loss: 0.3979 - val_accuracy: 0.8567 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4106 - accuracy: 0.8603\n",
      "Epoch 57: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4105 - accuracy: 0.8606 - val_loss: 0.4165 - val_accuracy: 0.8483 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.8220\n",
      "Epoch 58: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.5008 - accuracy: 0.8198 - val_loss: 0.5226 - val_accuracy: 0.7650 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4795 - accuracy: 0.8119\n",
      "Epoch 59: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.4795 - accuracy: 0.8119 - val_loss: 0.3962 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4755 - accuracy: 0.8344\n",
      "Epoch 60: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.4734 - accuracy: 0.8352 - val_loss: 0.4518 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4613 - accuracy: 0.8389\n",
      "Epoch 61: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4620 - accuracy: 0.8385 - val_loss: 0.4104 - val_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4784 - accuracy: 0.8257\n",
      "Epoch 62: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4784 - accuracy: 0.8257 - val_loss: 0.4075 - val_accuracy: 0.8633 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4387 - accuracy: 0.8504\n",
      "Epoch 63: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4390 - accuracy: 0.8504 - val_loss: 0.3752 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4282 - accuracy: 0.8526\n",
      "Epoch 64: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.4282 - accuracy: 0.8526 - val_loss: 0.4040 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4200 - accuracy: 0.8596\n",
      "Epoch 65: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4198 - accuracy: 0.8596 - val_loss: 0.4025 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4213 - accuracy: 0.8551\n",
      "Epoch 66: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.4202 - accuracy: 0.8557 - val_loss: 0.3739 - val_accuracy: 0.8717 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4171 - accuracy: 0.8584\n",
      "Epoch 67: val_loss did not improve from 0.37340\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4165 - accuracy: 0.8589 - val_loss: 0.3892 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4022 - accuracy: 0.8605\n",
      "Epoch 68: val_loss improved from 0.37340 to 0.36341, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4015 - accuracy: 0.8607 - val_loss: 0.3634 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4009 - accuracy: 0.8671\n",
      "Epoch 69: val_loss did not improve from 0.36341\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4011 - accuracy: 0.8672 - val_loss: 0.4257 - val_accuracy: 0.8683 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4151 - accuracy: 0.8566\n",
      "Epoch 70: val_loss did not improve from 0.36341\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4144 - accuracy: 0.8570 - val_loss: 0.3933 - val_accuracy: 0.8733 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4043 - accuracy: 0.8583\n",
      "Epoch 71: val_loss did not improve from 0.36341\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.4042 - accuracy: 0.8581 - val_loss: 0.4107 - val_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3945 - accuracy: 0.8668\n",
      "Epoch 72: val_loss improved from 0.36341 to 0.34931, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3942 - accuracy: 0.8669 - val_loss: 0.3493 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3887 - accuracy: 0.8673\n",
      "Epoch 73: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.3907 - accuracy: 0.8665 - val_loss: 0.3582 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3820 - accuracy: 0.8692\n",
      "Epoch 74: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3832 - accuracy: 0.8681 - val_loss: 0.3951 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4009 - accuracy: 0.8668\n",
      "Epoch 75: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.4002 - accuracy: 0.8669 - val_loss: 0.3557 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3955 - accuracy: 0.8648\n",
      "Epoch 76: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3955 - accuracy: 0.8648 - val_loss: 0.3704 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3746 - accuracy: 0.8715\n",
      "Epoch 77: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3746 - accuracy: 0.8715 - val_loss: 0.3494 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3834 - accuracy: 0.8724\n",
      "Epoch 78: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 5s 31ms/step - loss: 0.3841 - accuracy: 0.8720 - val_loss: 0.4049 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3871 - accuracy: 0.8687\n",
      "Epoch 79: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 5s 31ms/step - loss: 0.3871 - accuracy: 0.8687 - val_loss: 0.3658 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3840 - accuracy: 0.8681\n",
      "Epoch 80: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3846 - accuracy: 0.8680 - val_loss: 0.4190 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8649\n",
      "Epoch 81: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3867 - accuracy: 0.8654 - val_loss: 0.3507 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8714\n",
      "Epoch 82: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3798 - accuracy: 0.8719 - val_loss: 0.3906 - val_accuracy: 0.8567 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4228 - accuracy: 0.8661\n",
      "Epoch 83: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.4227 - accuracy: 0.8661 - val_loss: 0.4412 - val_accuracy: 0.8283 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3921 - accuracy: 0.8613\n",
      "Epoch 84: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3928 - accuracy: 0.8611 - val_loss: 0.3671 - val_accuracy: 0.8683 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4326 - accuracy: 0.8600\n",
      "Epoch 85: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4326 - accuracy: 0.8600 - val_loss: 0.4105 - val_accuracy: 0.8383 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3929 - accuracy: 0.8651\n",
      "Epoch 86: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3925 - accuracy: 0.8654 - val_loss: 0.3939 - val_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3770 - accuracy: 0.8685\n",
      "Epoch 87: val_loss did not improve from 0.34931\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3783 - accuracy: 0.8680 - val_loss: 0.3760 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3640 - accuracy: 0.8765\n",
      "Epoch 88: val_loss improved from 0.34931 to 0.34316, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3640 - accuracy: 0.8763 - val_loss: 0.3432 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3677 - accuracy: 0.8754\n",
      "Epoch 89: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3678 - accuracy: 0.8752 - val_loss: 0.3861 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3606 - accuracy: 0.8737\n",
      "Epoch 90: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3609 - accuracy: 0.8735 - val_loss: 0.3737 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3580 - accuracy: 0.8798\n",
      "Epoch 91: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3574 - accuracy: 0.8802 - val_loss: 0.3858 - val_accuracy: 0.8500 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4651 - accuracy: 0.8365\n",
      "Epoch 92: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4650 - accuracy: 0.8361 - val_loss: 0.3883 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4234 - accuracy: 0.8361\n",
      "Epoch 93: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.4241 - accuracy: 0.8357 - val_loss: 0.3736 - val_accuracy: 0.8633 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4119 - accuracy: 0.8543\n",
      "Epoch 94: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 4s 25ms/step - loss: 0.4119 - accuracy: 0.8543 - val_loss: 0.3543 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.8306 - accuracy: 0.8344\n",
      "Epoch 95: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.8306 - accuracy: 0.8344 - val_loss: 0.3944 - val_accuracy: 0.8633 - lr: 0.0010\n",
      "Epoch 96/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.8507\n",
      "Epoch 96: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4155 - accuracy: 0.8507 - val_loss: 0.3751 - val_accuracy: 0.8683 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4008 - accuracy: 0.8551\n",
      "Epoch 97: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4014 - accuracy: 0.8544 - val_loss: 0.4078 - val_accuracy: 0.8517 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.8559\n",
      "Epoch 98: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3977 - accuracy: 0.8559 - val_loss: 0.3868 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4173 - accuracy: 0.8531\n",
      "Epoch 99: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4169 - accuracy: 0.8531 - val_loss: 0.3479 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4001 - accuracy: 0.8579\n",
      "Epoch 100: val_loss did not improve from 0.34316\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3996 - accuracy: 0.8581 - val_loss: 0.3438 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 101/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3791 - accuracy: 0.8674\n",
      "Epoch 101: val_loss improved from 0.34316 to 0.33661, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3791 - accuracy: 0.8674 - val_loss: 0.3366 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3958 - accuracy: 0.8698\n",
      "Epoch 102: val_loss did not improve from 0.33661\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3958 - accuracy: 0.8694 - val_loss: 0.3811 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3718 - accuracy: 0.8709\n",
      "Epoch 103: val_loss improved from 0.33661 to 0.33310, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3733 - accuracy: 0.8706 - val_loss: 0.3331 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3739 - accuracy: 0.8696\n",
      "Epoch 104: val_loss did not improve from 0.33310\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3742 - accuracy: 0.8689 - val_loss: 0.3556 - val_accuracy: 0.8700 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3692 - accuracy: 0.8728\n",
      "Epoch 105: val_loss improved from 0.33310 to 0.32774, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3686 - accuracy: 0.8731 - val_loss: 0.3277 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3596 - accuracy: 0.8757\n",
      "Epoch 106: val_loss did not improve from 0.32774\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3596 - accuracy: 0.8757 - val_loss: 0.3344 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4403 - accuracy: 0.8565\n",
      "Epoch 107: val_loss did not improve from 0.32774\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4393 - accuracy: 0.8570 - val_loss: 0.3902 - val_accuracy: 0.8617 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4500 - accuracy: 0.8578\n",
      "Epoch 108: val_loss did not improve from 0.32774\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4500 - accuracy: 0.8578 - val_loss: 0.3351 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4018 - accuracy: 0.8608\n",
      "Epoch 109: val_loss did not improve from 0.32774\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.4031 - accuracy: 0.8602 - val_loss: 0.3541 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Epoch 110/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3808 - accuracy: 0.8726\n",
      "Epoch 110: val_loss did not improve from 0.32774\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3808 - accuracy: 0.8726 - val_loss: 0.3460 - val_accuracy: 0.9017 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3641 - accuracy: 0.8802\n",
      "Epoch 111: val_loss improved from 0.32774 to 0.31494, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3644 - accuracy: 0.8802 - val_loss: 0.3149 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3536 - accuracy: 0.8807\n",
      "Epoch 112: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3536 - accuracy: 0.8807 - val_loss: 0.3299 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3538 - accuracy: 0.8752\n",
      "Epoch 113: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3534 - accuracy: 0.8752 - val_loss: 0.3600 - val_accuracy: 0.8717 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4790 - accuracy: 0.8564\n",
      "Epoch 114: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.4794 - accuracy: 0.8559 - val_loss: 0.3908 - val_accuracy: 0.8517 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4021 - accuracy: 0.8559\n",
      "Epoch 115: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4023 - accuracy: 0.8559 - val_loss: 0.3361 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4135 - accuracy: 0.8621\n",
      "Epoch 116: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4140 - accuracy: 0.8613 - val_loss: 0.3478 - val_accuracy: 0.8917 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3600 - accuracy: 0.8750\n",
      "Epoch 117: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3600 - accuracy: 0.8750 - val_loss: 0.3579 - val_accuracy: 0.8633 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3532 - accuracy: 0.8784\n",
      "Epoch 118: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3535 - accuracy: 0.8783 - val_loss: 0.3246 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3514 - accuracy: 0.8817\n",
      "Epoch 119: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3516 - accuracy: 0.8819 - val_loss: 0.3539 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3440 - accuracy: 0.8823\n",
      "Epoch 120: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3434 - accuracy: 0.8826 - val_loss: 0.3291 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3456 - accuracy: 0.8784\n",
      "Epoch 121: val_loss did not improve from 0.31494\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3458 - accuracy: 0.8785 - val_loss: 0.3328 - val_accuracy: 0.8783 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3377 - accuracy: 0.8847\n",
      "Epoch 122: val_loss improved from 0.31494 to 0.30195, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3378 - accuracy: 0.8846 - val_loss: 0.3019 - val_accuracy: 0.8933 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3402 - accuracy: 0.8850\n",
      "Epoch 123: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3402 - accuracy: 0.8850 - val_loss: 0.3744 - val_accuracy: 0.8633 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.8581\n",
      "Epoch 124: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.6709 - accuracy: 0.8581 - val_loss: 0.4441 - val_accuracy: 0.8050 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.5699 - accuracy: 0.8204\n",
      "Epoch 125: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.5699 - accuracy: 0.8204 - val_loss: 0.3826 - val_accuracy: 0.8650 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4600 - accuracy: 0.8578\n",
      "Epoch 126: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.4602 - accuracy: 0.8567 - val_loss: 0.4810 - val_accuracy: 0.8317 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.4196 - accuracy: 0.8499\n",
      "Epoch 127: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4199 - accuracy: 0.8496 - val_loss: 0.3609 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3979 - accuracy: 0.8709\n",
      "Epoch 128: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3993 - accuracy: 0.8700 - val_loss: 0.3812 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8631\n",
      "Epoch 129: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3920 - accuracy: 0.8635 - val_loss: 0.3510 - val_accuracy: 0.8817 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3855 - accuracy: 0.8649\n",
      "Epoch 130: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3871 - accuracy: 0.8639 - val_loss: 0.3332 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3695 - accuracy: 0.8756\n",
      "Epoch 131: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3695 - accuracy: 0.8756 - val_loss: 0.3379 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3668 - accuracy: 0.8689\n",
      "Epoch 132: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3662 - accuracy: 0.8691 - val_loss: 0.3234 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3771 - accuracy: 0.8731\n",
      "Epoch 133: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3768 - accuracy: 0.8731 - val_loss: 0.3550 - val_accuracy: 0.8700 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3564 - accuracy: 0.8743\n",
      "Epoch 134: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3564 - accuracy: 0.8743 - val_loss: 0.3689 - val_accuracy: 0.8567 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3507 - accuracy: 0.8782\n",
      "Epoch 135: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3496 - accuracy: 0.8785 - val_loss: 0.3387 - val_accuracy: 0.8717 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3396 - accuracy: 0.8826\n",
      "Epoch 136: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3396 - accuracy: 0.8826 - val_loss: 0.3193 - val_accuracy: 0.8800 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3502 - accuracy: 0.8811\n",
      "Epoch 137: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3502 - accuracy: 0.8813 - val_loss: 0.3206 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3321 - accuracy: 0.8828\n",
      "Epoch 138: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3321 - accuracy: 0.8828 - val_loss: 0.3231 - val_accuracy: 0.8900 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3226 - accuracy: 0.8900\n",
      "Epoch 139: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3241 - accuracy: 0.8894 - val_loss: 0.3483 - val_accuracy: 0.8717 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3451 - accuracy: 0.8819\n",
      "Epoch 140: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3449 - accuracy: 0.8819 - val_loss: 0.3244 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4207 - accuracy: 0.8565\n",
      "Epoch 141: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.4207 - accuracy: 0.8565 - val_loss: 0.3820 - val_accuracy: 0.8583 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3705 - accuracy: 0.8677\n",
      "Epoch 142: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3701 - accuracy: 0.8680 - val_loss: 0.3786 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3646 - accuracy: 0.8718\n",
      "Epoch 143: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.3655 - accuracy: 0.8717 - val_loss: 0.3392 - val_accuracy: 0.8850 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3525 - accuracy: 0.8836\n",
      "Epoch 144: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3518 - accuracy: 0.8835 - val_loss: 0.3114 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.9824 - accuracy: 0.8582\n",
      "Epoch 145: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.9775 - accuracy: 0.8574 - val_loss: 0.3498 - val_accuracy: 0.8867 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3809 - accuracy: 0.8720\n",
      "Epoch 146: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3804 - accuracy: 0.8722 - val_loss: 0.3339 - val_accuracy: 0.8883 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.5277 - accuracy: 0.8625\n",
      "Epoch 147: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.5270 - accuracy: 0.8626 - val_loss: 0.3487 - val_accuracy: 0.8733 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3585 - accuracy: 0.8730\n",
      "Epoch 148: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3576 - accuracy: 0.8733 - val_loss: 0.3379 - val_accuracy: 0.8750 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.4008 - accuracy: 0.8658\n",
      "Epoch 149: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.4003 - accuracy: 0.8663 - val_loss: 0.3466 - val_accuracy: 0.8767 - lr: 0.0010\n",
      "Epoch 150/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3471 - accuracy: 0.8830\n",
      "Epoch 150: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3468 - accuracy: 0.8833 - val_loss: 0.3631 - val_accuracy: 0.8667 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3508 - accuracy: 0.8765\n",
      "Epoch 151: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3509 - accuracy: 0.8765 - val_loss: 0.3687 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 152/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3443 - accuracy: 0.8789\n",
      "Epoch 152: val_loss did not improve from 0.30195\n",
      "\n",
      "Epoch 152: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3436 - accuracy: 0.8789 - val_loss: 0.3626 - val_accuracy: 0.8617 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3423 - accuracy: 0.8761\n",
      "Epoch 153: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3423 - accuracy: 0.8761 - val_loss: 0.3132 - val_accuracy: 0.8850 - lr: 8.0000e-04\n",
      "Epoch 154/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3350 - accuracy: 0.8787\n",
      "Epoch 154: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3344 - accuracy: 0.8789 - val_loss: 0.3479 - val_accuracy: 0.8717 - lr: 8.0000e-04\n",
      "Epoch 155/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3298 - accuracy: 0.8801\n",
      "Epoch 155: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3301 - accuracy: 0.8804 - val_loss: 0.3156 - val_accuracy: 0.8867 - lr: 8.0000e-04\n",
      "Epoch 156/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3252 - accuracy: 0.8834\n",
      "Epoch 156: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3248 - accuracy: 0.8837 - val_loss: 0.3149 - val_accuracy: 0.8850 - lr: 8.0000e-04\n",
      "Epoch 157/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.8780\n",
      "Epoch 157: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3335 - accuracy: 0.8778 - val_loss: 0.3171 - val_accuracy: 0.8767 - lr: 8.0000e-04\n",
      "Epoch 158/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.8830\n",
      "Epoch 158: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3240 - accuracy: 0.8833 - val_loss: 0.3160 - val_accuracy: 0.8900 - lr: 8.0000e-04\n",
      "Epoch 159/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3257 - accuracy: 0.8806\n",
      "Epoch 159: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3268 - accuracy: 0.8802 - val_loss: 0.3223 - val_accuracy: 0.8667 - lr: 8.0000e-04\n",
      "Epoch 160/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3315 - accuracy: 0.8865\n",
      "Epoch 160: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3312 - accuracy: 0.8865 - val_loss: 0.3065 - val_accuracy: 0.8983 - lr: 8.0000e-04\n",
      "Epoch 161/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.8869\n",
      "Epoch 161: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3159 - accuracy: 0.8867 - val_loss: 0.3062 - val_accuracy: 0.8950 - lr: 8.0000e-04\n",
      "Epoch 162/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3214 - accuracy: 0.8894\n",
      "Epoch 162: val_loss did not improve from 0.30195\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3214 - accuracy: 0.8881 - val_loss: 0.3420 - val_accuracy: 0.8817 - lr: 8.0000e-04\n",
      "Epoch 163/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3266 - accuracy: 0.8883\n",
      "Epoch 163: val_loss improved from 0.30195 to 0.29902, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3266 - accuracy: 0.8883 - val_loss: 0.2990 - val_accuracy: 0.8967 - lr: 8.0000e-04\n",
      "Epoch 164/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3596 - accuracy: 0.8875\n",
      "Epoch 164: val_loss improved from 0.29902 to 0.29301, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 31ms/step - loss: 0.3595 - accuracy: 0.8874 - val_loss: 0.2930 - val_accuracy: 0.8983 - lr: 8.0000e-04\n",
      "Epoch 165/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3159 - accuracy: 0.8903\n",
      "Epoch 165: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3147 - accuracy: 0.8906 - val_loss: 0.3099 - val_accuracy: 0.8917 - lr: 8.0000e-04\n",
      "Epoch 166/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3187 - accuracy: 0.8928\n",
      "Epoch 166: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3186 - accuracy: 0.8928 - val_loss: 0.3278 - val_accuracy: 0.8733 - lr: 8.0000e-04\n",
      "Epoch 167/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3046 - accuracy: 0.8954\n",
      "Epoch 167: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3046 - accuracy: 0.8954 - val_loss: 0.3251 - val_accuracy: 0.8817 - lr: 8.0000e-04\n",
      "Epoch 168/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3060 - accuracy: 0.8918\n",
      "Epoch 168: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3063 - accuracy: 0.8915 - val_loss: 0.3031 - val_accuracy: 0.8900 - lr: 8.0000e-04\n",
      "Epoch 169/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3024 - accuracy: 0.8962\n",
      "Epoch 169: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3025 - accuracy: 0.8963 - val_loss: 0.3514 - val_accuracy: 0.8700 - lr: 8.0000e-04\n",
      "Epoch 170/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3230 - accuracy: 0.8876\n",
      "Epoch 170: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3227 - accuracy: 0.8878 - val_loss: 0.3007 - val_accuracy: 0.8950 - lr: 8.0000e-04\n",
      "Epoch 171/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.8888\n",
      "Epoch 171: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3090 - accuracy: 0.8885 - val_loss: 0.3611 - val_accuracy: 0.8617 - lr: 8.0000e-04\n",
      "Epoch 172/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2983 - accuracy: 0.8960\n",
      "Epoch 172: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.2980 - accuracy: 0.8961 - val_loss: 0.3160 - val_accuracy: 0.8900 - lr: 8.0000e-04\n",
      "Epoch 173/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3242 - accuracy: 0.8804\n",
      "Epoch 173: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3240 - accuracy: 0.8802 - val_loss: 0.3011 - val_accuracy: 0.8900 - lr: 8.0000e-04\n",
      "Epoch 174/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3560 - accuracy: 0.8812\n",
      "Epoch 174: val_loss did not improve from 0.29301\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3547 - accuracy: 0.8815 - val_loss: 0.3239 - val_accuracy: 0.8817 - lr: 8.0000e-04\n",
      "Epoch 175/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3104 - accuracy: 0.8903\n",
      "Epoch 175: val_loss improved from 0.29301 to 0.28939, saving model to best_model_v1.h5\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3100 - accuracy: 0.8904 - val_loss: 0.2894 - val_accuracy: 0.9033 - lr: 8.0000e-04\n",
      "Epoch 176/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3024 - accuracy: 0.8973\n",
      "Epoch 176: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3034 - accuracy: 0.8965 - val_loss: 0.3275 - val_accuracy: 0.8867 - lr: 8.0000e-04\n",
      "Epoch 177/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3024 - accuracy: 0.8941\n",
      "Epoch 177: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3024 - accuracy: 0.8941 - val_loss: 0.2926 - val_accuracy: 0.8967 - lr: 8.0000e-04\n",
      "Epoch 178/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2942 - accuracy: 0.8963\n",
      "Epoch 178: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2942 - accuracy: 0.8963 - val_loss: 0.3347 - val_accuracy: 0.8817 - lr: 8.0000e-04\n",
      "Epoch 179/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2857 - accuracy: 0.9006\n",
      "Epoch 179: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2857 - accuracy: 0.9006 - val_loss: 0.3240 - val_accuracy: 0.8800 - lr: 8.0000e-04\n",
      "Epoch 180/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.9006\n",
      "Epoch 180: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2810 - accuracy: 0.9009 - val_loss: 0.3188 - val_accuracy: 0.8900 - lr: 8.0000e-04\n",
      "Epoch 181/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2879 - accuracy: 0.8997\n",
      "Epoch 181: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2879 - accuracy: 0.8996 - val_loss: 0.3487 - val_accuracy: 0.8700 - lr: 8.0000e-04\n",
      "Epoch 182/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3095 - accuracy: 0.8869\n",
      "Epoch 182: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3093 - accuracy: 0.8872 - val_loss: 0.3231 - val_accuracy: 0.8817 - lr: 8.0000e-04\n",
      "Epoch 183/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3606 - accuracy: 0.8804\n",
      "Epoch 183: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.3601 - accuracy: 0.8806 - val_loss: 0.3969 - val_accuracy: 0.8417 - lr: 8.0000e-04\n",
      "Epoch 184/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.8678\n",
      "Epoch 184: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.4707 - accuracy: 0.8678 - val_loss: 0.3632 - val_accuracy: 0.8550 - lr: 8.0000e-04\n",
      "Epoch 185/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3246 - accuracy: 0.8869\n",
      "Epoch 185: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3249 - accuracy: 0.8869 - val_loss: 0.3264 - val_accuracy: 0.8833 - lr: 8.0000e-04\n",
      "Epoch 186/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3503 - accuracy: 0.8859\n",
      "Epoch 186: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3504 - accuracy: 0.8857 - val_loss: 0.3420 - val_accuracy: 0.8933 - lr: 8.0000e-04\n",
      "Epoch 187/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3051 - accuracy: 0.8951\n",
      "Epoch 187: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.3060 - accuracy: 0.8948 - val_loss: 0.3929 - val_accuracy: 0.8517 - lr: 8.0000e-04\n",
      "Epoch 188/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2936 - accuracy: 0.8962\n",
      "Epoch 188: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2934 - accuracy: 0.8963 - val_loss: 0.3126 - val_accuracy: 0.8883 - lr: 8.0000e-04\n",
      "Epoch 189/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2898 - accuracy: 0.9003\n",
      "Epoch 189: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2893 - accuracy: 0.9004 - val_loss: 0.3795 - val_accuracy: 0.8567 - lr: 8.0000e-04\n",
      "Epoch 190/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3403 - accuracy: 0.8820\n",
      "Epoch 190: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3403 - accuracy: 0.8820 - val_loss: 0.3247 - val_accuracy: 0.8917 - lr: 8.0000e-04\n",
      "Epoch 191/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2923 - accuracy: 0.8971\n",
      "Epoch 191: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.2919 - accuracy: 0.8972 - val_loss: 0.2980 - val_accuracy: 0.8933 - lr: 8.0000e-04\n",
      "Epoch 192/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2942 - accuracy: 0.8906\n",
      "Epoch 192: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2942 - accuracy: 0.8907 - val_loss: 0.3752 - val_accuracy: 0.8650 - lr: 8.0000e-04\n",
      "Epoch 193/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3531 - accuracy: 0.8795\n",
      "Epoch 193: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3520 - accuracy: 0.8800 - val_loss: 0.3190 - val_accuracy: 0.8850 - lr: 8.0000e-04\n",
      "Epoch 194/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3063 - accuracy: 0.8961\n",
      "Epoch 194: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3062 - accuracy: 0.8965 - val_loss: 0.3201 - val_accuracy: 0.8800 - lr: 8.0000e-04\n",
      "Epoch 195/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2878 - accuracy: 0.8984\n",
      "Epoch 195: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.2884 - accuracy: 0.8983 - val_loss: 0.3168 - val_accuracy: 0.8850 - lr: 8.0000e-04\n",
      "Epoch 196/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2970 - accuracy: 0.8940\n",
      "Epoch 196: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2977 - accuracy: 0.8941 - val_loss: 0.3842 - val_accuracy: 0.8433 - lr: 8.0000e-04\n",
      "Epoch 197/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3009 - accuracy: 0.8930\n",
      "Epoch 197: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.3009 - accuracy: 0.8933 - val_loss: 0.3409 - val_accuracy: 0.8783 - lr: 8.0000e-04\n",
      "Epoch 198/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2727 - accuracy: 0.9031\n",
      "Epoch 198: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.2728 - accuracy: 0.9031 - val_loss: 0.3552 - val_accuracy: 0.8617 - lr: 8.0000e-04\n",
      "Epoch 199/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2882 - accuracy: 0.8965\n",
      "Epoch 199: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.2888 - accuracy: 0.8961 - val_loss: 0.3507 - val_accuracy: 0.8817 - lr: 8.0000e-04\n",
      "Epoch 200/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2937 - accuracy: 0.9004\n",
      "Epoch 200: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2941 - accuracy: 0.9006 - val_loss: 0.3587 - val_accuracy: 0.8650 - lr: 8.0000e-04\n",
      "Epoch 201/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3316 - accuracy: 0.8885\n",
      "Epoch 201: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3316 - accuracy: 0.8885 - val_loss: 0.3217 - val_accuracy: 0.8833 - lr: 8.0000e-04\n",
      "Epoch 202/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2889 - accuracy: 0.8960\n",
      "Epoch 202: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2889 - accuracy: 0.8959 - val_loss: 0.3262 - val_accuracy: 0.8833 - lr: 8.0000e-04\n",
      "Epoch 203/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9042\n",
      "Epoch 203: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2682 - accuracy: 0.9041 - val_loss: 0.3260 - val_accuracy: 0.8750 - lr: 8.0000e-04\n",
      "Epoch 204/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3319 - accuracy: 0.8986\n",
      "Epoch 204: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3312 - accuracy: 0.8989 - val_loss: 0.3315 - val_accuracy: 0.8767 - lr: 8.0000e-04\n",
      "Epoch 205/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3701 - accuracy: 0.8825\n",
      "Epoch 205: val_loss did not improve from 0.28939\n",
      "\n",
      "Epoch 205: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.3710 - accuracy: 0.8815 - val_loss: 0.3474 - val_accuracy: 0.8700 - lr: 8.0000e-04\n",
      "Epoch 206/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.3346 - accuracy: 0.8831\n",
      "Epoch 206: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3346 - accuracy: 0.8831 - val_loss: 0.3156 - val_accuracy: 0.8917 - lr: 6.4000e-04\n",
      "Epoch 207/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3192 - accuracy: 0.8890\n",
      "Epoch 207: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3188 - accuracy: 0.8889 - val_loss: 0.3073 - val_accuracy: 0.8983 - lr: 6.4000e-04\n",
      "Epoch 208/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3177 - accuracy: 0.8973\n",
      "Epoch 208: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3175 - accuracy: 0.8970 - val_loss: 0.3010 - val_accuracy: 0.8983 - lr: 6.4000e-04\n",
      "Epoch 209/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2866 - accuracy: 0.9054\n",
      "Epoch 209: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.2866 - accuracy: 0.9054 - val_loss: 0.3425 - val_accuracy: 0.8717 - lr: 6.4000e-04\n",
      "Epoch 210/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2830 - accuracy: 0.8986\n",
      "Epoch 210: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.2828 - accuracy: 0.8985 - val_loss: 0.3402 - val_accuracy: 0.8800 - lr: 6.4000e-04\n",
      "Epoch 211/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2794 - accuracy: 0.9012\n",
      "Epoch 211: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2801 - accuracy: 0.9011 - val_loss: 0.3482 - val_accuracy: 0.8650 - lr: 6.4000e-04\n",
      "Epoch 212/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2723 - accuracy: 0.8980\n",
      "Epoch 212: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2740 - accuracy: 0.8976 - val_loss: 0.3048 - val_accuracy: 0.8983 - lr: 6.4000e-04\n",
      "Epoch 213/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2636 - accuracy: 0.9021\n",
      "Epoch 213: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2648 - accuracy: 0.9009 - val_loss: 0.3156 - val_accuracy: 0.8933 - lr: 6.4000e-04\n",
      "Epoch 214/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2676 - accuracy: 0.9055\n",
      "Epoch 214: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 29ms/step - loss: 0.2685 - accuracy: 0.9050 - val_loss: 0.3544 - val_accuracy: 0.8783 - lr: 6.4000e-04\n",
      "Epoch 215/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2745 - accuracy: 0.9002\n",
      "Epoch 215: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2745 - accuracy: 0.9002 - val_loss: 0.3391 - val_accuracy: 0.8683 - lr: 6.4000e-04\n",
      "Epoch 216/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2922 - accuracy: 0.9003\n",
      "Epoch 216: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2919 - accuracy: 0.9004 - val_loss: 0.3424 - val_accuracy: 0.8683 - lr: 6.4000e-04\n",
      "Epoch 217/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2820 - accuracy: 0.8973\n",
      "Epoch 217: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2823 - accuracy: 0.8972 - val_loss: 0.3518 - val_accuracy: 0.8717 - lr: 6.4000e-04\n",
      "Epoch 218/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.9014\n",
      "Epoch 218: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 30ms/step - loss: 0.2715 - accuracy: 0.9017 - val_loss: 0.3412 - val_accuracy: 0.8817 - lr: 6.4000e-04\n",
      "Epoch 219/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.9010\n",
      "Epoch 219: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 31ms/step - loss: 0.2724 - accuracy: 0.9006 - val_loss: 0.3464 - val_accuracy: 0.8583 - lr: 6.4000e-04\n",
      "Epoch 220/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.3208 - accuracy: 0.8879\n",
      "Epoch 220: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3214 - accuracy: 0.8876 - val_loss: 0.3061 - val_accuracy: 0.8933 - lr: 6.4000e-04\n",
      "Epoch 221/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2764 - accuracy: 0.9033\n",
      "Epoch 221: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 25ms/step - loss: 0.2764 - accuracy: 0.9033 - val_loss: 0.3526 - val_accuracy: 0.8633 - lr: 6.4000e-04\n",
      "Epoch 222/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.9029\n",
      "Epoch 222: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2665 - accuracy: 0.9033 - val_loss: 0.3057 - val_accuracy: 0.8900 - lr: 6.4000e-04\n",
      "Epoch 223/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3118 - accuracy: 0.8862\n",
      "Epoch 223: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.3119 - accuracy: 0.8863 - val_loss: 0.3122 - val_accuracy: 0.8867 - lr: 6.4000e-04\n",
      "Epoch 224/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2768 - accuracy: 0.9014\n",
      "Epoch 224: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2771 - accuracy: 0.9017 - val_loss: 0.3281 - val_accuracy: 0.8683 - lr: 6.4000e-04\n",
      "Epoch 225/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2688 - accuracy: 0.9048\n",
      "Epoch 225: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2677 - accuracy: 0.9054 - val_loss: 0.3572 - val_accuracy: 0.8633 - lr: 6.4000e-04\n",
      "Epoch 226/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.3034 - accuracy: 0.9007\n",
      "Epoch 226: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.3043 - accuracy: 0.9000 - val_loss: 0.3445 - val_accuracy: 0.8683 - lr: 6.4000e-04\n",
      "Epoch 227/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2855 - accuracy: 0.8997\n",
      "Epoch 227: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2852 - accuracy: 0.8998 - val_loss: 0.3193 - val_accuracy: 0.8817 - lr: 6.4000e-04\n",
      "Epoch 228/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2657 - accuracy: 0.9053\n",
      "Epoch 228: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.2654 - accuracy: 0.9056 - val_loss: 0.3199 - val_accuracy: 0.8933 - lr: 6.4000e-04\n",
      "Epoch 229/1000\n",
      "169/169 [==============================] - ETA: 0s - loss: 0.2595 - accuracy: 0.9078\n",
      "Epoch 229: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.2595 - accuracy: 0.9078 - val_loss: 0.3491 - val_accuracy: 0.8767 - lr: 6.4000e-04\n",
      "Epoch 230/1000\n",
      "167/169 [============================>.] - ETA: 0s - loss: 0.2557 - accuracy: 0.9061\n",
      "Epoch 230: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 4s 27ms/step - loss: 0.2550 - accuracy: 0.9065 - val_loss: 0.3398 - val_accuracy: 0.8850 - lr: 6.4000e-04\n",
      "Epoch 231/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2545 - accuracy: 0.9070\n",
      "Epoch 231: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2538 - accuracy: 0.9074 - val_loss: 0.3478 - val_accuracy: 0.8850 - lr: 6.4000e-04\n",
      "Epoch 232/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2851 - accuracy: 0.9053\n",
      "Epoch 232: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 28ms/step - loss: 0.2851 - accuracy: 0.9052 - val_loss: 0.3027 - val_accuracy: 0.8767 - lr: 6.4000e-04\n",
      "Epoch 233/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2694 - accuracy: 0.9027\n",
      "Epoch 233: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2691 - accuracy: 0.9026 - val_loss: 0.3281 - val_accuracy: 0.8633 - lr: 6.4000e-04\n",
      "Epoch 234/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2643 - accuracy: 0.9035\n",
      "Epoch 234: val_loss did not improve from 0.28939\n",
      "169/169 [==============================] - 5s 27ms/step - loss: 0.2642 - accuracy: 0.9037 - val_loss: 0.3166 - val_accuracy: 0.8767 - lr: 6.4000e-04\n",
      "Epoch 235/1000\n",
      "168/169 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9055Restoring model weights from the end of the best epoch: 175.\n",
      "\n",
      "Epoch 235: val_loss did not improve from 0.28939\n",
      "\n",
      "Epoch 235: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.\n",
      "169/169 [==============================] - 4s 26ms/step - loss: 0.2558 - accuracy: 0.9054 - val_loss: 0.3052 - val_accuracy: 0.8850 - lr: 6.4000e-04\n",
      "Epoch 235: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=1000,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, model_checkpoint,\n",
    "              tf.keras.callbacks.ReduceLROnPlateau(\n",
    "                  monitor='val_loss',\n",
    "                  factor=0.8,\n",
    "                  patience=30,\n",
    "                  verbose=1\n",
    "              )],\n",
    "    class_weight=class_weight_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9656532",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
